#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\use_default_options true
\begin_modules
algorithm2e
theorems-ams-chap-bytype
theorems-ams-extended-chap-bytype
tabs-within-sections
figs-within-sections
eqs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "tgtermes" "default"
\font_sans "tgheros" "default"
\font_typewriter "tgcursor" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1.5cm
\topmargin 1.5cm
\rightmargin 1.5cm
\bottommargin 1.5cm
\secnumdepth 3
\tocdepth 4
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
The definitions in this note may not be taken as formal definitions, mere
 explanations.
\end_layout

\begin_layout Chapter
Intro
\end_layout

\begin_layout Standard
Abstract and formal tasks that are among the most diffuclt mental undertakings
 for a human being are among the easiest for a computer.
\end_layout

\begin_layout Definition
Knowledge base approach
\end_layout

\begin_layout Definition
A computer reason about statements in formal languages automatically using
 logical inference rules.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
machine learning
\end_layout

\begin_layout Definition
the capability for AI systems to acquire knowledge by extracting patterns
 from raw data.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Machine learning algorithms rely heavily on the representation of data,
 what the features are.
\end_layout

\begin_layout Definition
representation learning
\end_layout

\begin_layout Definition
Using machine learning to discover not only the mapping form representation
 to output but also the representation itself.
\end_layout

\begin_layout Example*
Autoencoder: the combination of an encoer that converts the input data into
 a different representation and a decoder that converts it back into the
 original format.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
factors of variation
\end_layout

\begin_layout Definition
sources of incluence that help us make sense of the rich variability in
 the data
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
Deep learning
\end_layout

\begin_layout Definition
Deep learning learns the right represetation for the data, allowing the
 computer to learn a multi-stp computer program.
\end_layout

\begin_layout Standard
The depth of computational graph or the depth of the graph describing how
 concepts are related to each other (the depth of the probabilistic modeling
 graph).
\end_layout

\begin_layout Example*
multilayer perceptron
\end_layout

\begin_layout Standard
There are two main ways of measuring the depth of a model.
 The first view is based on the number of sequential instructions that must
 be executed to evaluate the architecture.
 Another approach, used by deep probabilistic models, regards the depth
 of a model as being not the depth of the computational graph but the depth
 of the graph describing how concepts are related to each other.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted6.png

\end_inset


\end_layout

\begin_layout Part
Mathematical Basics
\end_layout

\begin_layout Chapter
Numerical computation basics
\end_layout

\begin_layout Section
Overflow and underflow
\end_layout

\begin_layout Standard
Underflow occurs when numbers near zero are rounded to zero.
 Many functions behave qualitatively differently when their argument is
 zero rather than a small positive number.
\end_layout

\begin_layout Standard
Overflow occurs when numbers with large magnitutde are approximated as 
\begin_inset Formula $\infty$
\end_inset

 or 
\begin_inset Formula $-\infty$
\end_inset

.
\end_layout

\begin_layout Example*
\begin_inset CommandInset href
LatexCommand href
name "Softmax"
target "https://en.wikipedia.org/wiki/Softmax_function"
literal "false"

\end_inset


\end_layout

\begin_layout Example*
The standard (unit) softmax function 
\begin_inset Formula $\sigma\colon\mathbb{R}^{K}\to\mathbb{R}^{K}$
\end_inset

 
\begin_inset Formula 
\[
\sigma\left(\mathbf{z}\right)_{i}=\frac{e^{z_{i}}}{\sum_{j=1}^{K}e^{z_{j}}}\quad\text{for }i=1,\dots,K\text{ and }\mathbf{z}=\left(z_{1},\dots,z_{K}\right)\in\mathbb{R}^{K}
\]

\end_inset

The output of the softmax function can be used to represent a categorical
 distribution, a probability distribution over 
\begin_inset Formula $K$
\end_inset

 different outcomes.
\end_layout

\begin_layout Example*
Given a very large or small 
\begin_inset Formula $z_{i}$
\end_inset

, 
\begin_inset Formula $e^{z_{i}}$
\end_inset

 may go to infinity.
 The value of the softmax function is not changed analytically by adding
 or subtracting a scalar from the input, which leads to the solution 
\begin_inset Formula $z=x-\max_{i}x_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Poor Condition
\end_layout

\begin_layout Definition
Conditioning
\end_layout

\begin_layout Definition
the rate in which a funciton changes w.r.t.
 small changes in its inputs.
\end_layout

\begin_layout Remark
Funcitons that change rapidly when their inputs are perturbed slightly can
 be problematic for scientific computation because rounding errors in the
 inputs can result in large changes in the output.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Gradient-Based optimization
\end_layout

\begin_layout Standard
terminology here: cost function = loss function = error function
\end_layout

\begin_layout Subsection
Gradient descent
\end_layout

\begin_layout Standard
\begin_inset Formula $f\left(x-\varepsilon\text{sign}\left(f^{\prime}\left(x\right)\right)\right)$
\end_inset

 is less than 
\begin_inset Formula $f\left(x\right)$
\end_inset

 for small enough 
\begin_inset Formula $\varepsilon$
\end_inset

, thus we can reduce 
\begin_inset Formula $f\left(x\right)$
\end_inset

 by moving 
\begin_inset Formula $x$
\end_inset

 in small steps with opposite sign of the derivative.
\end_layout

\begin_layout Standard
For functions with multiple inputs, to minimize 
\begin_inset Formula $f$
\end_inset

 and find the direction in which 
\begin_inset Formula $f$
\end_inset

 decreases the fastest
\begin_inset Formula 
\[
\underset{u,\left\lVert u\right\rVert =1}{\min}u^{T}\triangledown_{x}f\left(x\right)=\underset{u,\left\lVert u\right\rVert =1}{\min}\left\lVert u\right\rVert \left\lVert \triangledown_{x}f\left(x\right)\right\rVert \cos\theta
\]

\end_inset

where 
\begin_inset Formula $\theta$
\end_inset

 is the angle between 
\begin_inset Formula $u$
\end_inset

 and the gradient.
 This can simplifies to 
\begin_inset Formula 
\[
\underset{u}{\min}\cos\theta
\]

\end_inset

where the gradient points uphill.
 Thus we should decrease 
\begin_inset Formula $f$
\end_inset

 by moving in the direction of the negative gradient, giving the following
 algorithm
\begin_inset Formula 
\[
\boldsymbol{x}^{\prime}=\boldsymbol{x}-\varepsilon\triangledown_{x}f\left(\boldsymbol{x}\right)
\]

\end_inset

where 
\begin_inset Formula $\epsilon$
\end_inset

 is the 
\emph on
learning rate, 
\emph default
a positive scalar determining the size of the step.
 A popular approach to set 
\begin_inset Formula $\epsilon$
\end_inset

 it a small constant.
 Another approach is to evaluate 
\begin_inset Formula $f\left(x-\epsilon\triangledown_{x}f\left(x\right)\right)$
\end_inset

 for several values of 
\begin_inset Formula $\epsilon$
\end_inset

 and choose the one that results in the smallest objective function value,
 which method is called a 
\emph on
line search
\emph default
.
\end_layout

\begin_layout Section
Jacobian and Hessian Matrix
\end_layout

\begin_layout Standard
The second derivative can be seen as 
\emph on
curvature.
\end_layout

\begin_layout Standard
The Hessian matrix of continuous functions has the property that 
\begin_inset Formula 
\[
H_{i,j}=H_{j,i}
\]

\end_inset

which is the case for most of the functions in the context of deep learning.
\end_layout

\begin_layout Subsection
The optimal step size and Hessian matrix
\end_layout

\begin_layout Standard
About the second derivative, 
\begin_inset CommandInset href
LatexCommand href
name "here"
target "https://math.stackexchange.com/questions/2573376/second-directional-derivative-and-hessian-matrix"
literal "false"

\end_inset

.
 The second directional derivative is represented 
\begin_inset Formula 
\[
d^{T}Hd
\]

\end_inset

where 
\begin_inset Formula $d$
\end_inset

 is the unit vector in that direction.
 
\begin_inset CommandInset href
LatexCommand href
name "Decompose the Hessian matrix into"
target "https://en.wikipedia.org/wiki/Symmetric_matrix#Decomposition"
literal "false"

\end_inset


\begin_inset Formula 
\[
d^{T}Q\Lambda Q^{T}d.
\]

\end_inset

The directional second derivative is a weighted average of all of the eigenvalue
s, with weights between 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

 and eigenvectors that have smaller angle with 
\begin_inset Formula $d$
\end_inset

 receiving more weight.
\end_layout

\begin_layout Standard
By Taylor series and gradient descent
\begin_inset Formula 
\[
f\left(x^{\left(0\right)}-\epsilon g\right)\approx f\left(x^{\left(0\right)}\right)-\epsilon g^{T}g+\frac{1}{2}\epsilon^{2}g^{T}Hg.
\]

\end_inset

The last two terms determine how gradient descent performs.
 When 
\begin_inset Formula $g^{T}Hg$
\end_inset

 is positive, the optimal step size that decreases 
\begin_inset Formula $f$
\end_inset

 (why?)
\begin_inset Formula 
\[
\epsilon^{*}=\frac{g^{T}g}{g^{T}Hg}.
\]

\end_inset


\end_layout

\begin_layout Subsection
Second derivative and local minimum/maximum
\end_layout

\begin_layout Standard
At a critical point, it is possible to examine the eigenvalues of the Hessianto
 determine whether the critical point is a local maximum, local minimum,
 or saddle point.
 By inspecting the second directional derivative
\begin_inset Formula 
\[
d^{T}Hd
\]

\end_inset


\end_layout

\begin_layout Standard
1.
 
\begin_inset Formula $H$
\end_inset

 positive definite, the point is a local mininum;
\end_layout

\begin_layout Standard
2.
 
\begin_inset Formula $H$
\end_inset

 negative definite, the point is a local maximum.
\end_layout

\begin_layout Standard
There might be cases where one eigenvalue of 
\begin_inset Formula $H$
\end_inset

 is positive and another is nagative, which implies a saddle point.
\end_layout

\begin_layout Subsection
Condition number of Hessian matrix
\end_layout

\begin_layout Standard
When the Hessian has a poor condition number, gradient descent performs
 poorly.
 Gradient descent is unaware of this change in the derivative so it does
 nto know that it needs to explore preferentially in the direction where
 the derivative remains nagative for longer.
 It also makes it difficult to choose a good step size.
\end_layout

\begin_layout Subsection
Newton's method
\end_layout

\begin_layout Standard
To avoid the above issue, one can use information from Hessian matrix to
 guide the search.
 The simplest method is known as Newton's method.
\end_layout

\begin_layout Standard
Solve for the critical point of the second-order Taylor series expansion
 of 
\begin_inset Formula $f$
\end_inset

 near some point 
\begin_inset Formula $\mathbf{x}$
\end_inset


\begin_inset Formula 
\[
\mathbf{x}^{*}=\mathbf{x}^{\left(0\right)}-H\left(f\right)\left(\mathbf{x}^{\left(0\right)}\right)^{-1}\triangledown_{x}f\left(\mathbf{x}^{\left(0\right)}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
When 
\begin_inset Formula $f$
\end_inset

 is positive definite quadratic function, this method can be applied to
 compute the minumum directly.
 Otherwise, iteratively applying this method can reach the critical point
 much faster thatn gradient descent.
 However, this method is not suitable for saddle point case.
\end_layout

\begin_layout Standard
Deep learning algorithms tend to lack guarantees because the family of functions
 used in deep learning is quite complicated.
 The dominant approach in many other fields to optimization is to design
 optimization algorithms for a limited family of functions.
\end_layout

\begin_layout Standard
Lipschitz continuity and convex optimization may give good guarantee.
 Convex optimization is used only as a subroutine of some deep learning
 algorithms since most problems in deep learning are difficult to express
 in terms of convex optimization.
\end_layout

\begin_layout Section
Constrained Optimization
\end_layout

\begin_layout Standard
One simple approach to constrained optimization is to modify gradient descent
 taking the constraint into account.
\end_layout

\begin_layout Standard
Another sophisticated approach is to design a different unconstrained optimizati
on whose solution can be converted into a solution to the original constrained
 optimization problem.
 e.g.
 converting a optimization with constrained that 
\begin_inset Formula $x$
\end_inset

 have exactly unit norm into 
\begin_inset Formula $g\left(\theta\right)=f\left(\left[\cos\theta,\sin\theta\right]\right)$
\end_inset

.
\end_layout

\begin_layout Standard
A very general solution to contrained optimization is Karush-Kuhn-Tucker
 appraoch.
 The constrained set is described by a set of equalities and inequalites
\begin_inset Formula 
\[
S=\left\{ \mathbf{x}|\forall i,g^{\left(i\right)}\left(\mathbf{x}\right)=0\text{ and }\forall j,h^{\left(i\right)}\left(\mathbf{x}\right)\leq0\right\} .
\]

\end_inset

The generalized Lagrangian is defined as
\begin_inset Formula 
\[
L\left(\mathbf{x},\lambda,\alpha\right)=f\left(\mathbf{x}\right)+\sum_{i}\lambda_{i}g^{\left(i\right)}\left(\mathbf{x}\right)+\sum_{j}\alpha_{j}h^{\left(j\right)}\left(\mathbf{x}\right).
\]

\end_inset

where 
\begin_inset Formula $\lambda_{i}$
\end_inset

 and 
\begin_inset Formula $\alpha_{i}$
\end_inset

 are called 
\emph on
KKT mutlipliers, 
\emph default
which functions is unconstraiend.
 As 
\begin_inset Formula 
\[
\max_{\lambda}\max_{\alpha,\alpha\geq0}L\left(\mathbf{x},\mathbf{\lambda},\alpha\right)=f\left(x\right)
\]

\end_inset

while violated constraints result in 
\begin_inset Formula 
\[
\max_{\lambda}\max_{\alpha,\alpha\geq0}L\left(\mathbf{x},\mathbf{\lambda},\alpha\right)=\infty.
\]

\end_inset


\end_layout

\begin_layout Standard
A simple set of necessary properties describe the optimal points of constained
 optimization problems:
\end_layout

\begin_layout Enumerate
The gradient of the generalized Langrangian is zero;
\end_layout

\begin_layout Enumerate
All constraints on both 
\begin_inset Formula $\mathbf{x}$
\end_inset

 and the KKT multipliers are satisfied;
\end_layout

\begin_layout Enumerate
the inequality constraints exhibit complementary slackness: 
\begin_inset Formula $\alpha\odot h\left(x\right)=0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Chapter
Machine Learning Basics
\end_layout

\begin_layout Standard
Machine learning is essentially a form of applied statistics with increased
 emphasis on the use of computers to statistically estimate complicated
 functions and a decreased emphasis on proving confidence intervals around
 these funcitons.
\end_layout

\begin_layout Standard
The challenge of fitting the training data differs from the chanllenge of
 finding patterns that generalizes to new data.
 Most machine learning algorithms have settings called 
\emph on
hyperparameters
\emph default
 that must be determined external to the learning algorithm itself.
\end_layout

\begin_layout Section
Learning Algorithms, What Is That?
\end_layout

\begin_layout Definition*
A computer program is said to learn from experience 
\begin_inset Formula $E$
\end_inset

 with respect to some class of tasks 
\begin_inset Formula $T$
\end_inset

 and performance measure 
\begin_inset Formula $P$
\end_inset

, if its performance at tasks in 
\begin_inset Formula $T$
\end_inset

, as measured by 
\begin_inset Formula $P$
\end_inset

, improves with experience 
\begin_inset Formula $E$
\end_inset

.
\end_layout

\begin_layout Definition*
Machine learning tasks are usually described in terms of how the machine
 learning system should process an example, a collection of features that
 have been quantitively measured from some object or event that we want
 the machine learning systems to process.
 These tasks can be classfication, classification with missing inputs (in
 which case, a set of functions each of which deals with a subset of the
 input vector must be found), regression, transcript (OCR, speech recognition
 et al.), machine translation, 
\begin_inset CommandInset href
LatexCommand href
name "structured output"
target "https://en.wikipedia.org/wiki/Structured_prediction"
literal "false"

\end_inset

 (parsed tree, image segmentation, image caption), anomaly detection, synthesis
 and sampling, imputation of missing values, denoising, density eestimation.
\end_layout

\begin_layout Definition*
The perfomance measure 
\begin_inset Formula $P$
\end_inset

 is usually specific to the task 
\begin_inset Formula $T$
\end_inset

 being carried out by the system.
 For tasks such as classification, classification with missing inputs, and
 transcription, we measure the 
\emph on
accuracy
\emph default
 of the model, or 
\emph on
error rate
\emph default
.
 For tasks such as density estimation, the most common approach is to report
 the average log-probability the model assigns to some examples.
 We evaluate the performance measure using a 
\emph on
test set 
\emph default
of data that is separate from the data used for training.
\end_layout

\begin_layout Definition*
Machine learning algorithms can be broadly categorized as 
\emph on
unsupervised
\emph default
 or 
\emph on
supervised
\emph default
 by what kind of experience they are allowed to have during the learning
 process.
 Unsupervised learning and supervised learning are not formally defined
 terms.
 The lines between them are often blurred.
 The chain rule decomposition means that we can solve the ostensibly unsupervise
d problem into 
\begin_inset Formula $n$
\end_inset

 supervised learning problems.
 Some machine learning algorithms do not just experience a fixed dataset
 (reinforcement learning algorithms interact with an environment).
 Most machine learning algorithms simply experience a dataset.
 One common way of describing a dataset is with a 
\emph on
design
\emph default
 
\emph on
matrix
\emph default
.
 A design matrix is a matrix containing a different example in each row.
 Each column of the matrix corresponds to a different feature.
\end_layout

\begin_layout Section
Capacity, Overfitting and Underfitting
\end_layout

\begin_layout Standard
The central challenge in machine learning is that we must perform well on
 new, previously unseen inputs.
 The factors determining how well a machine learning algorithm will perform
 are its ability to make the training error small and make the gap between
 training and test error small.
 We first assume the underlying 
\emph on
data generating distribution 
\emph default
is independently indentically distributed.
\end_layout

\begin_layout Standard
We can control whether a model is more likely to overfit or underfit by
 altering its 
\emph on
capacity
\emph default
 (a model’s capacity is its ability to fit a wide variety of funcitons).
 One way to control the capacity of a learning algorithm is by choosing
 its 
\emph on
hypothesis
\emph default
 
\emph on
space
\emph default
, the set of functions that the learning algorithm is allowed to select
 as being the solution (like linear regression is restricted to linear functions
).
 Machine learning algorithms will generally perform best when their capacity
 is appropriate for the true complexity of the task they need to perform
 and the amount of training data they are provided with.
 The capacity of a model is not only determined by its 
\emph on
representational capacity.
 
\emph default
Additional limitations such as the imperfection of the optimization algorithm
 can make the 
\emph on
effective capacity 
\emph default
less thant the representational capacity of the model family.
\end_layout

\begin_layout Standard

\emph on
\begin_inset CommandInset href
LatexCommand href
name "Vapnik-Chervonenkis dimension"
target "https://en.wikipedia.org/wiki/Vapnik–Chervonenkis_dimension"
literal "false"

\end_inset

 
\emph default
is the most well-known means of quantifying model capacity.
 
\begin_inset Formula $H$
\end_inset

 can be seen as a set of functions and 
\begin_inset Formula $C$
\end_inset

 is the data set.
 The VC dimension of 
\begin_inset Formula $H$
\end_inset

 is the cardinality of the data set that 
\begin_inset Formula $H$
\end_inset

 shatters.
 The most important results in statistical learning theory show that the
 discrepancy between training error and generalization error is bounded
 from above by a quantity that grows as the model capacity grows but shrinks
 as the number of training examples increases.
\end_layout

\begin_layout Standard
Non-parametric models???? TODO
\end_layout

\begin_layout Standard
Bayes Error ???
\end_layout

\begin_layout Standard
The 
\emph on
no free lunch theorem
\emph default
 for machine learning states that averaged over all possible data generating
 distributions, every classifcation algorithm has the smae error rate when
 classifying prevously unobserved points.
 In other words, no machine learning algorithm is universally any better
 than any other.
 However, if we make assumptions about the kinds of probability distributions
 we encounter in real-world applications, we can design learning algorithms
 that perform well on these distributions.
 The goal of machine learning research is not to seek a universal learning
 algorithm or the absolute best learning algorithm.
\end_layout

\begin_layout Standard
The behavior of our algorithm is strongly affected not just by how large
 we make the set of functions allowed in its hypothesis space, but by the
 specific identity of those functions.
 We can give a learning algorithm a preference for one solution in its hypothesi
s space to another.
 Weight decay is a kind of perference added to a cost function.
 Expressing preferences for one function over another is a more general
 way of controlling a model’s capacity than including or excluding members
 from the hypothesis space.
 Regularization is any modification we make to a learning algorithm that
 is intended to reduce its generalization error but not its training error.
 Regularization is one of the central concerns of the field of machine learning,
 rivaled by its importantce only by 
\emph on
optimization.
\end_layout

\begin_layout Section
Hyperparameters and Validation Sets
\end_layout

\begin_layout Standard
Most machine learning algorithms have several settings that we can use to
 control the behavior of the learning algorithm, called 
\emph on
hyperparameters
\emph default
.
 To choose a proper hyperparameter, we need a 
\emph on
validation set 
\emph default
of examples that the training algorithm does not observe.
 We construct the validation set from the training data.
 The validation set is used to estimate the generalization error during
 or after training, allowing for the hyperparameteres to be updated accordingly.
 Typically, 
\begin_inset Formula $80\%$
\end_inset

 of the training data for training and 
\begin_inset Formula $20\%$
\end_inset

 for validation.
\end_layout

\begin_layout Standard
When the dataset is too small to be divided into disjoint parts, we use
 cross-validation.
 It is based on the idea of repeating the training and testing computation
 on different randomly chosen subsets or splits of the original dataset.
 The most common of these is the 
\begin_inset Formula $k$
\end_inset

-fold cross validation procedure.
\end_layout

\begin_layout Section
Estimators, Bias, and Variance
\end_layout

\begin_layout Standard
Foundational concept such as parameter estimation, bias and variance are
 useful to formally characterize notions of genralization, underfitting
 and overfitting.
 Bias and variance measure two different sources of error in an estimator.
 Bias measures the expected deviation from the true value of the function
 or parameter.
 Variance on the other hand, provides a measure of the deviation from the
 expected estimator value that any particular sampling of the data is likely
 to cause.
\end_layout

\begin_layout Subsection
Estimation
\end_layout

\begin_layout Standard
Point estimation provides the single best prediction of some quantity of
 interest.
 In general, the quantity of interest can be a single parameter or a vector
 parameter in some parametric model.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\left\{ x^{\left(1\right)},x^{\left(2\right)},\dots,x^{\left(m\right)}\right\} $
\end_inset

 be a set of 
\begin_inset Formula $m$
\end_inset

 i.i.d data points.
 A 
\emph on
point estimator 
\emph default
or 
\emph on
statistic 
\emph default
is any function of the data
\begin_inset Formula 
\[
\hat{\theta}=g\left(x^{\left(1\right)},\dots,x^{\left(m\right)}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\hat{\theta}$
\end_inset

 is a random variable.
\end_layout

\begin_layout Standard
Point estimation can also refer to the estimation of the relationship between
 input and target variables, also called 
\emph on
function estimators.
 
\emph default
The function estimator 
\begin_inset Formula $\hat{f}$
\end_inset

 is simply a point estimator in function space.
 Linear regression can be seen as an example of estimating a function from
 
\begin_inset Formula $x$
\end_inset

 to 
\begin_inset Formula $y$
\end_inset

 .
\end_layout

\begin_layout Subsection
Bias (about the accuracy of an estimator)
\end_layout

\begin_layout Standard
The bias of an estimator is defined as 
\begin_inset Formula 
\[
\text{bias}\left(\hat{\theta}_{m}\right)=E\left(\hat{\theta}_{m}\right)-\theta.
\]

\end_inset


\end_layout

\begin_layout Standard
where the expectation is over the data and 
\begin_inset Formula $\theta$
\end_inset

 is the true underlying value used to define the data generating distribution.
 An estimator 
\begin_inset Formula $\hat{\theta}_{m}$
\end_inset

 is said to be 
\emph on
unbiased
\emph default
 if 
\begin_inset Formula $\text{bias}\left(\hat{\theta}_{m}\right)=0$
\end_inset

.
 An estimator 
\begin_inset Formula $\hat{\theta}_{m}$
\end_inset

 is said to be 
\emph on
asymptotically unbiased 
\emph default
if 
\begin_inset Formula $\lim_{m\to\infty}\text{bias}\left(\hat{\theta}_{m}\right)=0$
\end_inset

.
 Unbiased estimators are not always the best estimators.
\end_layout

\begin_layout Subsection
Variance and Standard Error (about the dispersion of an estimator)
\end_layout

\begin_layout Standard
The variance of an estimator is simply the variance 
\begin_inset Formula 
\[
\text{Var}\left(\hat{\theta}\right)
\]

\end_inset

where the random variable is the training set.
 Alternatively, the standard error is denoted 
\begin_inset Formula $\text{SE}\left(\hat{\theta}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
The variance or the standard error of an estimator provides a measure of
 how we would expect the estimate we compute from data to vary as we independent
ly resample the dataset from the underlying data generating process.
 We would like to have it low.
\end_layout

\begin_layout Standard
The standard error of the mean is given by
\begin_inset Formula 
\[
\text{SE}\left(\hat{\mu}_{m}\right)=\sqrt{\text{Var}\left[\frac{1}{m}\sum_{i=1}^{m}x^{\left(i\right)}\right]}=\frac{\sigma}{\sqrt{m}}.
\]

\end_inset

However, neither the square root of the sample variance or the square root
 of the unbiased estimator of the variance provide an unbiased estimate
 of the standard deviation.
 They tend to underestimate the true standard deviation, but are still in
 use in practice.
 For large 
\begin_inset Formula $m$
\end_inset

, the approximation is quite reasonable.
\end_layout

\begin_layout Standard
The standard error of the mean is very useful in machine learning experiments.
 We often estimate the generalization error by computing
\emph on
 the sample mean of the error
\emph default
 on the test set.
 The number of examples in the test set determines the accuracy of this
 estimate.
 Using this estimation, by the central limit theorem, we can compute the
 probability that the true expectation falls in any chose interval.
\end_layout

\begin_layout Standard
It is a common property of popular estimators that the variance of the estimator
 decreases as a function of 
\begin_inset Formula $m$
\end_inset

, the number of examples in the dataset.
\end_layout

\begin_layout Subsection
Trading off Bias and Variance
\end_layout

\begin_layout Standard
If we are to minimize the mean squared error of the estimates, which measures
 the overall expected deviation between the estimator and the true value
 of the parameter 
\begin_inset Formula $\theta$
\end_inset

.
\begin_inset Formula 
\begin{align*}
\text{MSE} & =E\left[\left(\hat{\theta}_{m}-\theta\right)^{2}\right]\\
 & =\text{Bias}\left(\hat{\theta}_{m}\right)^{2}+\text{Var}\left(\hat{\theta}_{m}\right).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Desirable estimators are those with small MSE and these are estimators that
 manage to keep both their bias and variance somewhat in check.
\end_layout

\begin_layout Subsection
Consistency
\end_layout

\begin_layout Definition
Consistency
\end_layout

\begin_layout Definition
For any 
\begin_inset Formula $\varepsilon>0$
\end_inset


\begin_inset Formula 
\[
P\left(\left|\hat{\theta}_{m}-\theta\right|>\varepsilon\right)\to0
\]

\end_inset

as 
\begin_inset Formula $m\to0$
\end_inset

.
\end_layout

\begin_layout Definition
Consistency ensure that the bias induced by the estimator diminishes as
 the number of data example grows.
 Asymptotic unbiasedness does not imply consistency.
\end_layout

\begin_layout Section
Stochastic Gradient Descent
\end_layout

\begin_layout Standard
Nearly all of deep learning is powered by one very important algorithm:
 
\series bold
\emph on
schochastic gradient descent
\series default
\emph default
 or 
\series bold
SGD
\series default
, which is an extension of the gradient descent algorithm.
\end_layout

\begin_layout Standard
The cost function by a machine learning algorithm often decomposes as a
 sum over training examples of per-example loss function.
 The computational cost of the operation is 
\begin_inset Formula $O\left(m\right)$
\end_inset

.
 As the training set size grows to billions of examples, the time to take
 a single gradient step becomes prohibitively long.
\end_layout

\begin_layout Standard
The insight of stochastic gradient descent is that the gradient is an expectatio
n:
\begin_inset Formula 
\[
J\left(\theta\right)=E_{\mathbf{x},y\sim\hat{p}_{\text{data}}}L\left(x,y,\theta\right).
\]

\end_inset

The expectation may be approximately estimated using a small set of samples.
 On each step of the algorithm, a 
\emph on
minibatch
\emph default
 of examples are drawn uniformly from the training set.
 We may fit a training set with billions of examples using updates computed
 on only a hundred examples.
 The asymptotic cost of training a model with SGD is 
\begin_inset Formula $O\left(1\right)$
\end_inset

 as a function of 
\begin_inset Formula $m$
\end_inset

.
\end_layout

\begin_layout Part
Deep Networks: Modern Practices
\end_layout

\begin_layout Standard
Modern deep learning provides a very powerful framework for supervised learning.
 By adding more layers and more units within a layer, a deep network can
 represent functions of increasing complexity.
 Most tasks that consist of mapping an input vector to an output vector,
 and that are easy for a person to do rapidly, can be accomplished via deep
 learning, given sufficiently large models and sufficiently large datasets
 of labeled training examples.
\end_layout

\begin_layout Chapter
Deep Forward Networks
\end_layout

\begin_layout Standard
Feedforward networks, also called multiplayer perceptron, are the quintessential
 deep learning models.
 The goal of a feedforward network is to approximate a function 
\begin_inset Formula $f^{*}$
\end_inset

.
 Information flows through the function evaluated from 
\begin_inset Formula $x$
\end_inset

.
 There are no feedback connections in which outputs of the model are fed
 back into itself.
 When feedforward neural networks are extended to include feedback connections,
 they are called 
\series bold
\emph on
recurrent neural networks
\series default
\emph default
.
\end_layout

\begin_layout Standard
Feedforward neural networks are called neural because they are 
\emph on
loosely
\emph default
 inspired by neuroscience.
 these networks are called 
\emph on
networks
\emph default
 because they are typically represented by composing together many different
 functions.
 The model is associated with a directed acyclic graph describing how the
 functions are composed together.
 An example might be 
\begin_inset Formula 
\[
f\left(x\right)=f^{\left(3\right)}\left(f^{\left(2\right)}\left(f^{\left(1\right)}\left(x\right)\right)\right).
\]

\end_inset

The overall length of the chain is the 
\emph on
depth 
\emph default
of the model.
 The learning algorithm must decide how to use these layers to best implement
 an approximation of 
\begin_inset Formula $f^{*}$
\end_inset

.
\end_layout

\begin_layout Standard
A layer can be seen as a vector-to-vector function.
 A layer has many 
\emph on
units 
\emph default
that act in parallel.
 Each unit resembles a neuron in the sense that it receives input from many
 other units and computes its own activation value.
 
\end_layout

\begin_layout Standard
It is best to think of feedforward networks as function approximation machines
 that are designed to achieve statistical generalization, occasionally drawing
 some insights from what we know about the brain, rather than as models
 of brain function.
\end_layout

\begin_layout Standard
Deep learning addresses the limitations of linear models and kernel methods
 by learning the functions that map 
\begin_inset Formula $\mathbf{x}$
\end_inset

 to different feature dimensions to obtain a realiable non-linear function
 approximation.
 Instead of specifying the right function, practitioners specify the right
 family of functions.
\end_layout

\begin_layout Section
From cybernetics, connectionism to deep learning
\end_layout

\begin_layout Standard
Computational models of biological learning, models of how learning happens
 or could happen in the brain (ANNs)
\end_layout

\begin_layout Standard
The term 
\begin_inset Quotes eld
\end_inset

deep learning
\begin_inset Quotes erd
\end_inset

 appeals to a more general principle of learning 
\emph on
mutliple levels of compositions, 
\emph default
not necessarily neurally inspired.
 The earliest predecessors of modern deep learning were simple linear models
 motivated from a neuroscientific perspective.
 e.g.
 the McCulloch-Pitts neuron, ADALINE.
 Slightly modified versions of the stochastic gradient descent algorithm
 remian the dominant training algorithm for deep learning models today.
 Most neural networks today are based on a model neuron called the rectified
 linear unit.
 The original cognitron (Fukushima, 1975) introduced a more complicated
 version that was highly inspired by our knowledge of brain function.
 Today, neuroscience is regarded as an important source of inspiration for
 deep learning researchers, but it is no longer the predominant guide for
 the field.
 Actual neurons compute very different functions than modern rectified linear
 units, but greater neural realism has not yet led to an improvement in
 machine learning performance.
\end_layout

\begin_layout Standard
The central idea in connectionism is that a large number of simple computational
 units can achieve intelligent behavior when networked together.
 One of these concepts is that of distributed representation.
 Another major accomplishment of the connectionist movement was the suc-
 cessful use of back-propagation to train deep neural networks with internal
 repre- sentations and the popularization of the back-propagation algorithm.
\end_layout

\begin_layout Standard
The third wave of neural networks research began with a breakthrough in
 2006.
 This wave of neural networks research popularized the use of the term “deep
 learning” to emphasize that researchers were now able to train deeper neural
 networks than had been possible before, and to focus attention on the theoretic
al importance of depth.
\end_layout

\begin_layout Section
The age of Big Data
\end_layout

\begin_layout Standard
The age of Big Data has made machine learning much easier because the key
 burden of statistical estimation—generalizing well to new data after observing
 only a small amount of data has been considerably lightened.
\end_layout

\begin_layout Section
Increasing Model Sizes
\end_layout

\begin_layout Standard
Since the introduction of hidden units, artificial neural networks have
 doubled in size roughly every 2.4 years.
 This growth is driven by faster computers with larger memory and by the
 availability of larger datasets.
 Larger networks are able to achieve higher accuracy on more complex tasks.
 The increase in model size over time, due to the availability of faster
 CPUs, the advent of general purpose GPUs , faster network connectivity
 and better software infrastructure for distributed computing, is one of
 the most important trends in the history of deep learning.
\end_layout

\begin_layout Section
Increasing Accuracy, Complexity and Real-World Impact
\end_layout

\begin_layout Standard
Since the 1980s, deep learning has consistently improved in its ability
 to provide accurate recognition and prediction.
 Moreover, deep learning has consistently been applied with success to broader
 and broader sets of applications.
 
\end_layout

\begin_layout Standard
Another crowning achievement of deep learning is its extension to the domain
 of reinforcement learning.
 In the context of reinforcement learning, an autonomous agent must learn
 to perform a task by trial and error, without any guidance from the human
 operator.
 
\end_layout

\begin_layout Section
Convolutional Networks
\end_layout

\begin_layout Standard
Convolutional networks (LeCun, 1989), also known as convolutional neural
 networks, or CNNs, are a specialized kind of neural network for processing
 data that has a known grid-like topology.
 Convolutional networks are simply neural networks that use convolution
 in place of general matrix multiplication in at least one of their layers.
 
\end_layout

\begin_layout Standard
Usually, the operation used in a convolutional neural network does not correspon
d precisely to the definition of convolution as used in other fields, such
 as engineering or pure mathematics.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
s\left(t\right) & =\int x\left(a\right)w\left(t-a\right)da\\
 & =\sum_{a=-\infty}^{\infty}x\left(a\right)w\left(t-a\right)
\end{align*}

\end_inset

 
\begin_inset Formula $x$
\end_inset

 is referred to as 
\emph on
input
\emph default
 and 
\begin_inset Formula $w$
\end_inset

 as 
\emph on
kernel.
 
\emph default
the output 
\begin_inset Formula $s$
\end_inset

 sometimes as 
\emph on
feature map
\emph default
.
 In machine learning applications, the input is usually a multidimensional
 array of data, and the kernel is usually a multidimensional array of parameters
 that are adapted by the learning algorithm.
\end_layout

\begin_layout Standard
Many neural network libraries implement a related function called the cross-corr
elation, which is the same as convolution but without flipping the kernel.
 Many machine learning libraries implement cross-correlation but call it
 convolution.
 In the context of machine learning, the learning algorithm will learn the
 appropriate values of the kernel in the appropriate place, so an algorithm
 based on convolution with kernel flipping will learn a kernel that is flipped
 relative to the kernel learned by an algorithm without the flipping.
 Discrete convolution can be viewed as multiplication by a matrix, but the
 matrix has several entries constrained to be equal to other entries.
 convolution usually corresponds to a very sparse matrix (a matrix whose
 entries are mostly equal to zero).
\end_layout

\end_body
\end_document
