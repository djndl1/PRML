<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<meta name="generator" content="http://www.nongnu.org/elyxer/"/>
<meta name="create-date" content="2018-04-27"/>
<link rel="stylesheet" href="http://elyxer.nongnu.org/lyx.css" type="text/css" media="all"/>
<title>Converted document</title>
</head>
<body>
<div id="globalWrapper">
<div class="Unindented">
<span class="unknown">\
</span> <span class="unknown">\chapter</span>2. Probability Distribution<a class="Label" name="header-n0"> </a>
</div>
<div class="Indented">
<span class="unknown">\em</span><span class="unknown">\/</span>Density estimation
</div>
<div class="Indented">
Data points are independent and identically distributed. There are infinitely many probability distributions that could have given rise to the observed finite data set.
</div>
<div class="Indented">
<span class="unknown">\bfseries</span>Parametric and <span class="unknown">\bfseries</span>non-parametric approaches.
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--1"></a>2.3 The Gaussian Distribution
</h1>
<div class="Unindented">
<div class="formula">
<i>N</i>(<i>x</i>|<i>μ</i>, Σ|) = <span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator">(2<i>π</i>)<sup><i>D</i> ⁄ 2</sup></span><span class="ignored">)</span></span><span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator">|Σ|<sup>1 ⁄ 2</sup></span><span class="ignored">)</span></span>exp<span class="symbol">{</span> − <span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator">2</span><span class="ignored">)</span></span>(<i>x</i> − <i>μ</i>)<sup><i>T</i></sup>Σ<sup> − 1</sup>(<i>x</i> − <i>μ</i>)<span class="symbol">}</span>
</div>

</div>
<div class="Indented">
<span class="unknown">\em</span><span class="unknown">\/</span>Mahalanobis distance}: <span class="formula">Δ<sup>2</sup> = <span class="sqrt"><span class="radical">√</span><span class="ignored">(</span><span class="root">(<i>x</i> − <i>μ</i>)<sup><i>T</i></sup>Σ<sup> − 1</sup>(<i>x</i> − <i>μ</i>)</span><span class="ignored">)</span></span></span> and the quadratic form of the Gaussian distribution.
</div>
<div class="Indented">
<span class="unknown">\em</span><span class="unknown">\/</span>General, diagonal and <span class="unknown">\em</span><span class="unknown">\/</span>isotropic (<span class="formula">Σ = <i>σ</i><sup>2</sup><i>I</i></span>) covariace matrix
</div>
<div class="Indented">
A limitation of the Gaussian distribution is that it it intrinsically unimodal (i.e., has a single maximum) and so is unable to provide a godd approximation to multimodal distributions. The introduction of <span class="unknown">\em</span><span class="unknown">\/</span>latent variables, also called <span class="unknown">\em</span><span class="unknown">\/</span>hidden variables or <span class="unknown">\em</span><span class="unknown">\/</span>unobserved variables, allows both the covariance problem and the unimode problem to be addressed.
</div>
<h2 class="Subsection-">
<a class="toc" name="toc-Subsection--1"></a>2.3.1 Conditional and Marginal Gaussian distributions
</h2>
<div class="Unindented">
 An important property of the multivariate Gaussian distribution is that if two sets of variables are jointly Gaussian, then the conditional distribution of one set conditioned on the other is again. Similarly, the marginal distribution of either set is also Gaussian. <div class="formula">
<span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>μ</i><sub><i>a</i>|<i>b</i>|</sub>
</span>
<span class="arraycell align-c">
 = 
</span>
<span class="arraycell align-l">
<i>μ</i><sub><i>a</i></sub> + Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>ab</i></span></sub>Σ<span class="scripts"><sup class="script"> − 1</sup><sub class="script"><span class="ensuremath"><span class="unknown">\operatorname</span><i>bb</i></span></sub></span>(<i>x</i><sub><i>b</i></sub> − <i>μ</i><sub><i>b</i></sub>)
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-c">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
Σ<sub><i>a</i>|<i>b</i></sub>
</span>
<span class="arraycell align-c">
 = 
</span>
<span class="arraycell align-l">
Λ<span class="scripts"><sup class="script"> − 1</sup><sub class="script"><span class="ensuremath"><span class="unknown">\operatorname</span><i>aa</i></span></sub></span> = Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>aa</i></span></sub> − Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>ab</i></span></sub>Σ<span class="scripts"><sup class="script"> − 1</sup><sub class="script"><span class="ensuremath"><span class="unknown">\operatorname</span><i>bb</i></span></sub></span>Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>ba</i></span></sub>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-c">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
<i>p</i>(<i>x</i><sub><i>a</i></sub>)
</span>
<span class="arraycell align-c">
 = 
</span>
<span class="arraycell align-l">
<i>N</i>(<i>x</i><sub><i>a</i></sub>|<i>μ</i><sub><i>a</i></sub>, Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>aa</i></span></sub>|)
</span>

</span>
</span>
</div>
Given a joint Gaussian distribution <span class="formula"><i>N</i>(<i>x</i>|<i>μ</i>, Σ)</span>with <span class="formula">Λ = Σ<sup> − 1</sup></span> and <div class="formula">
<i>x</i> = <span class="array"><span class="arrayrow"><span class="bracket align-left">⎛</span></span><span class="arrayrow"><span class="bracket align-left">⎜</span></span><span class="arrayrow"><span class="bracket align-left">⎝</span></span></span><span class="array"><span class="arrayrow">
<span class="arraycell align-c">
<i>x</i><sub><i>a</i></sub>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
<i>x</i><sub><i>b</i></sub>
</span>

</span>
</span><span class="array"><span class="arrayrow"><span class="bracket align-right">⎞</span></span><span class="arrayrow"><span class="bracket align-right">⎟</span></span><span class="arrayrow"><span class="bracket align-right">⎠</span></span></span>,  <i>μ</i> = <span class="array"><span class="arrayrow"><span class="bracket align-left">⎛</span></span><span class="arrayrow"><span class="bracket align-left">⎜</span></span><span class="arrayrow"><span class="bracket align-left">⎝</span></span></span><span class="array"><span class="arrayrow">
<span class="arraycell align-c">
<i>μ</i><sub><i>a</i></sub>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
<i>μ</i><sub><i>b</i></sub>
</span>

</span>
</span><span class="array"><span class="arrayrow"><span class="bracket align-right">⎞</span></span><span class="arrayrow"><span class="bracket align-right">⎟</span></span><span class="arrayrow"><span class="bracket align-right">⎠</span></span></span>
</div>
<div class="formula">
Σ = <span class="array"><span class="arrayrow"><span class="bracket align-left">⎡</span></span><span class="arrayrow"><span class="bracket align-left">⎢</span></span><span class="arrayrow"><span class="bracket align-left">⎣</span></span></span><span class="array"><span class="arrayrow">
<span class="arraycell align-c">
Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>aa</i></span></sub>Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>ab</i></span></sub>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>ba</i></span></sub>Σ<sub><span class="ensuremath"><span class="unknown">\operatorname</span><i>bb</i></span></sub>
</span>

</span>
</span><span class="array"><span class="arrayrow"><span class="bracket align-right">⎤</span></span><span class="arrayrow"><span class="bracket align-right">⎥</span></span><span class="arrayrow"><span class="bracket align-right">⎦</span></span></span>
</div>

</div>
<div class="Indented">
<span class="unknown">\chapter</span>3. Linear Models for Regression<a class="Label" name="header-n10"> </a>
</div>
<div class="Indented">
 The goal of regression is to predict the value of one or more continuous <span class="unknown">\em</span><span class="unknown">\/</span>target variables <span class="formula"><i>t</i></span> given the value of a <span class="formula"><i>D</i></span>-dimensional vector <span class="formula"><i>x⃗</i></span> <span class="unknown">\em</span><span class="unknown">\/</span>input variables.
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--2"></a>3.1 Linear Basis Function Models
</h1>
<div class="Unindented">
<a class="Label" name="header-n13"> </a>
</div>
<div class="Indented">
<div class="formula">
<a class="eqnumber" name="eq-1">(1) </a><span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>y</i>(<i>x</i>, <i>w</i>) = 
</span>
<span class="arraycell align-l">
<i>w</i><sub>0</sub> + <span class="limits"><sup class="limit"><i>M</i> − 1</sup><span class="limit">⎲</span><span class="limit">⎳</span><sub class="limit"><i>j</i> = 1</sub></span><i>w</i><sub><i>j</i></sub><i>φ</i><sub><i>j</i></sub>(<i>x</i>)
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 = 
</span>
<span class="arraycell align-l">
<i>w</i><sup><i>T</i></sup><i>φ</i>(<i>x</i>)
</span>

</span>
</span>
</div>

</div>
<div class="Indented">
where <span class="formula"><i>φ</i><sub><i>j</i></sub>(<i>x⃗</i>)</span> are known as <span class="unknown">\em</span><span class="unknown">\/</span>basis functions, and <span class="formula"><i>w</i><sub>0</sub></span> <span class="unknown">\em</span><span class="unknown">\/</span>bias parameter.<br/>
 <span class="formula"><i>w</i> = (<i>w</i><sub>0</sub>, ..., <i>w</i><sub><i>M</i> − 1</sub>)<sup><i>T</i></sup></span> and <span class="formula"><i>φ</i> = (<i>φ</i><sub>0</sub>, ..., <i>φ</i><sub><i>M</i> − 1</sub>)<sup><i>T</i></sup></span>.
</div>
<div class="Indented">
By using nonlinear basis functions, we allow the function <span class="formula"><i>y</i>(<i>x</i>, <i>w</i>)</span> to be a non-linear function of the input vector <span class="formula"><i>x</i></span>. Thus Eq. above is called a <span class="unknown">\em</span><span class="unknown">\/</span>linear model.
</div>
<div class="Indented">
<span class="unknown">\bfseries</span>Choices for the basis functions
</div>
<div class="Indented">
<span class="unknown">\em</span><span class="unknown">\/</span>Gaussian: <div class="formula">
<i>φ</i><sub><i>j</i></sub>(<i>x</i>) = <i>exp</i><span class="array"><span class="arrayrow"><span class="bracket align-left">⎧</span></span><span class="arrayrow"><span class="bracket align-left">⎩</span></span></span> − <span class="fraction"><span class="ignored">(</span><span class="numerator">(<i>x</i> − <i>μ</i><sub><i>j</i></sub>)<sup>2</sup></span><span class="ignored">)/(</span><span class="denominator">2<i>s</i><sup>2</sup></span><span class="ignored">)</span></span><span class="array"><span class="arrayrow"><span class="bracket align-right">⎫</span></span><span class="arrayrow"><span class="bracket align-right">⎭</span></span></span>
</div>
where <span class="formula"><i>μ</i><sub><i>j</i></sub></span> govern the locations of the basis functions in input space.
</div>
<div class="Indented">
<span class="unknown">\em</span><span class="unknown">\/</span>Sigmoidal basis function:
</div>
<div class="Indented">
<div class="formula">
<a class="eqnumber" name="eq-2">(2) </a><span class="environment"><span class="arrayrow">
<span class="arraycell align-r">

</span>
<span class="arraycell align-l">
   <i>φ</i><sub><i>j</i></sub>(<i>x</i>) = <i>σ</i>(<span class="fraction"><span class="ignored">(</span><span class="numerator"><i>x</i> − <i>μ</i><sub><i>j</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>s</i></span><span class="ignored">)</span></span>)
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">

</span>
<span class="arraycell align-l">
<span class="text">where: </span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">

</span>
<span class="arraycell align-l">
   <i>σ</i>(<i>a</i>) = <span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator">1 + <i>exp</i>( − <i>a</i>)</span><span class="ignored">)</span></span>
</span>

</span>
</span>
</div>

</div>
<div class="Indented">
and <span class="formula"><i>tanh</i>(<i>a</i>) = 2<i>σ</i>(<i>a</i>) − 1</span>
</div>
<div class="Indented">
<span class="unknown">\em</span><span class="unknown">\/</span>The Fourier basis: Each basis function represents a specific frequency and has infinite spatial extent.
</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-1"></a>Maximum Likelihood and least squares
</div>
<div class="Unindented">
<a class="Label" name="header-n34"> </a>
</div>
<div class="Indented">
<a class="URL" href="https://en.wikipedia.org/wiki/Mode_(statistics)">Mode</a>
</div>
<div class="Indented">
Assume <span class="formula"><i>p</i>(<i>t</i>, |<i>X</i>, <i>w</i>, <i>β</i>) = <span class="scriptfont">N</span>(<i>t</i>|<i>y</i>, <i>β</i><sup> − 1</sup>)</span>,
</div>
<div class="Indented">
where <span class="formula"><i>t</i> = <i>y</i> + <i>ϵ</i></span> and <span class="formula"><i>y</i> = <i>w</i><sup><i>T</i></sup><i>φ</i>(<i>x</i>)</span>
</div>
<div class="Indented">
<div class="formula">
<a class="eqnumber" name="eq-3">(3) </a><span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>p</i>(<span class="mathrm">t</span>|<i>X</i>, <i>w</i>, <i>β</i>)
</span>
<span class="arraycell align-l">
 = <span class="limits"><sup class="limit"><i>N</i></sup><span class="limit">∏</span><sub class="limit"><i>n</i> = 1</sub></span><span class="scriptfont"> N</span>(<i>t</i><sub><i>n</i></sub>|<i>w</i><sup><i>T</i></sup><i>φ</i>(<i>x</i><sub><i>n</i></sub>), <i>β</i><sup> − 1</sup>)
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">

</span>
<span class="arraycell align-l">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>N</i></span><span class="ignored">)/(</span><span class="denominator">2</span><span class="ignored">)</span></span><i>ln</i><i>β</i> − <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>N</i></span><span class="ignored">)/(</span><span class="denominator">2</span><span class="ignored">)</span></span><i>ln</i>(2<i>π</i>) − <i>β</i><i>E</i><sub><i>D</i></sub>(<i>w</i>)
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">

</span>

</span>
</span>
</div>

</div>
<div class="Indented">
where <span class="formula"><span class="mathrm">t</span></span> is the column vector of targets and <div class="formula">
<i>E</i><sub><i>D</i></sub>(<i>w</i>) = <span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator">2</span><span class="ignored">)</span></span><span class="limits"><sup class="limit"><i>N</i></sup><span class="limit">⎲</span><span class="limit">⎳</span><sub class="limit"><i>n</i> = 1</sub></span>{<i>t</i><sub><i>n</i></sub> − <i>w</i><sup><i>T</i></sup><i>φ</i>(<i>x</i><sub><i>n</i></sub>)}<sup>2</sup>.
</div>
It is easy to see that maximization of the likelihood function under a conditional Gaussian noise distribution for a linear model is equivalent to minimizing a sum-of-squares error function. Take the gradient and set it to zero: <div class="formula">
<i>w</i><sub><i>ML</i></sub> = (Φ<sup><i>T</i></sup>Φ)<sup> − 1</sup>Φ<sup><i>T</i></sup><span class="mathrm">t</span>
</div>
where <span class="unknown">\em</span><span class="unknown">\/</span>design matrix <span class="formula">Φ</span> is given by <span class="formula">Φ<sub><i>nj</i></sub> = <i>φ</i><sub><i>j</i></sub>(<i>x</i><sub><i>n</i></sub>)</span>
</div>
<div class="Indented">
Take the derivative w.r.t. <span class="formula"><i>w</i><sub>0</sub></span> <div class="formula">
<i>w</i><sub>0</sub> = <span class="bar"><i>t</i></span> − <span class="limits"><sup class="limit"><i>N</i></sup><span class="limit">⎲</span><span class="limit">⎳</span><sub class="limit"><i>j</i> = 1</sub></span><i>w</i><sub><i>j</i></sub><span class="bar"><i>φ</i></span><sub><i>j</i></sub>
</div>
where <span class="formula"><span class="bar"><i>t</i></span></span> and <span class="formula"><span class="overline"><i>φ</i><sub><i>j</i></sub></span></span> are the arithmetic mean of their elements.
</div>
<div class="Indented">
Maximize the log likehood w.r.t. the noise precision parameter <span class="formula"><i>β</i></span>: <div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>β</i><sub><i>ML</i></sub></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>N</i></span><span class="ignored">)</span></span><span class="limits"><sup class="limit"><i>N</i></sup><span class="limit">⎲</span><span class="limit">⎳</span><sub class="limit"><i>n</i> = 1</sub></span>[<i>t</i><sub><i>n</i></sub> − <i>w</i><span class="scripts"><sup class="script"><i>T</i></sup><sub class="script"><i>ML</i></sub></span><i>φ</i>(<i>x</i><sub><i>n</i></sub>)]<sup>2</sup>
</div>

</div>
<div class="Indented">
The least-squares regression function (Euclidean distance) is obtained by finding the orthogonal projection of the data vector <span class="formula"><i>t</i></span> onto the subspace spanned by the basis functions <span class="formula"><i>φ</i><sub><i>j</i></sub>(<i>x</i>)</span> in which each basis function is viewed as a vector <span class="formula"><i>φ</i><sub><i>j</i></sub></span> of length <span class="unknown">\em</span><span class="unknown">\/</span>N with elements <span class="formula"><i>φ</i><sub><i>j</i></sub>(<i>x</i><sub><i>n</i></sub>)</span>.
</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-2"></a>Sequential learning (online algorithms)
</div>
<div class="Unindented">
<a class="Label" name="header-n55"> </a>
</div>
<div class="Indented">
<span class="unknown">\bfseries</span>Stochastic graidient descent (sequential gradient descent)
</div>
<div class="Indented">
<a class="URL" href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient descent</a>, see the description.
</div>
<div class="Indented">
Given an error function <span class="formula"><i>E</i> = <span class="limits"><span class="limit">∑</span></span><sub><i>n</i></sub><i>E</i><sub><i>n</i></sub></span> , a sum over data points, after presentation of pattern <span class="formula"><i>n</i></span><br/>

</div>
<div class="Indented">
<div class="formula">
<i>w</i><sup>(<i>t</i> + 1)</sup> = <i>w</i><sup>(<i>t</i>)</sup> − <i>η</i><span class="unknown">\triangledown</span><i>E</i><sub><i>n</i></sub>
</div>
where <span class="formula"><i>t</i></span> is the iteration number and <span class="formula"><i>η</i></span> is a <span class="unknown">\em</span><span class="unknown">\/</span>learning rate.
</div>
<div class="Indented">
<span class="unknown">\em</span><span class="unknown">\/</span>LMS (least-mean-squares) algorithm
</div>
<div class="Indented">
<span class="formula">  </span>For the case of the sum-of-squares error function: <div class="formula">
<span class="unknown">\triangledown</span><i>E</i><sub><i>n</i></sub> = (<i>t</i><sub><i>n</i></sub> − <i>w</i><sup>(<i>t</i>)<i>T</i></sup><i>φ</i><sub><i>n</i></sub>)<i>φ</i><sub><i>n</i></sub>
</div>

</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-3"></a>Regularized least squares
</div>
<div class="Unindented">
<a class="Label" name="header-n70"> </a> <div class="formula">
<i>E</i>(<i>x</i>) = <i>E</i><sub><i>D</i></sub> + <i>λ</i><i>E</i><sub><i>W</i></sub>
</div>
In general <span class="formula"><i>E</i><sub><i>W</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>λ</i></span><span class="ignored">)/(</span><span class="denominator">2</span><span class="ignored">)</span></span><span class="limits"><span class="limit">∑</span></span><span class="scripts"><sup class="script"><i>M</i></sup><sub class="script"><i>j</i> = 1</sub></span>|<i>w</i><sub><i>j</i></sub>|<sup><i>q</i></sup></span>
</div>
<div class="Indented">
<span class="formula"><i>q</i> = 1</span>: (lasso) if is large enough, some of the coefficients are driven to zero<br/>
  <span class="formula"><i>q</i> = 2</span>: <span class="formula"><i>E</i><sub><i>w</i></sub>(<i>q</i> = 2)</span> is known in ML as <span class="unknown">\em</span><span class="unknown">\/</span>weight decay, because in sequential learning algorithms, it encourages weight values to decay towards zero. In statistics, it is an example of a <span class="unknown">\em</span><span class="unknown">\/</span>parameter shrinkage method. <div class="formula">
<i>w</i> = (<i>λ</i><i>I</i> + Φ<sup><i>T</i></sup>Φ)<sup> − 1</sup>Φ<sup><i>T</i></sup><i>t</i>
</div>
<span class="unknown">\resizebox</span>!0.6<span class="unknown">\columnwidth</span><img class="embedded" src="PRML Part 1-1.eps" alt="figure PRML Part 1-1.eps"/>

</div>
<div class="Indented">
Consider this figure in a Langrange-multipliers way.
</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-4"></a>Multiple outputs
</div>
<div class="Unindented">
<a class="Label" name="header-n81"> </a>
</div>
<div class="Indented">
Of course we can decouple into multiple, independent regression problems, however there is an approach using the same set of basis functions so that y <div class="formula">
<i>y</i>(<i>x</i>, <i>w</i>) = <i>W</i><sup><i>T</i></sup><i>φ</i>(<i>x</i>)
</div>
and <div class="formula">
<i>p</i>(<span class="mathrm">t</span>|<i>x</i>, <i>W</i>, <i>β</i>) = <span class="scriptfont">N</span>(<span class="mathrm">t</span>|<i>W</i><sup><i>T</i></sup><i>φ</i>(<i>x</i>), <i>β</i><sup> − 1</sup><i>I</i>)
</div>
which yields <div class="formula">
<i>W</i><sub><i>ML</i></sub> = Φ<sup>†</sup><i>T</i>
</div>
 For the case of arbitrary covariance matrices, see MAL of multi-variate Gaussian distribution.
</div>

</div>
</body>
</html>
